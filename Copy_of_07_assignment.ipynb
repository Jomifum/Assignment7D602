{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jomifum/Assignment7D602/blob/main/Copy_of_07_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd2QZetSDszc"
      },
      "source": [
        "# **Assignment 7**\n",
        "#By Jose Fuentes\n",
        "\n",
        "# **Weeks 8 & 9 - Pandas**\n",
        "* In this homework assignment, you will explore and analyze a public dataset of your choosing. Since this assignment is “open-ended” in nature, you are free to expand upon the requirements below. However, you must meet the minimum requirments as indicated in each section.\n",
        "\n",
        "* You must use Pandas as the **primary tool** to process your data.\n",
        "\n",
        "* The preferred method for this analysis is in a .ipynb file. Feel free to use whichever platform of your choosing.  \n",
        " * https://www.youtube.com/watch?v=inN8seMm7UI (Getting started with Colab).\n",
        "\n",
        "* Your data should need some \"work\", or be considered \"dirty\".  You must show your skills in data cleaning/wrangling.\n",
        "\n",
        "### **Some data examples:**\n",
        "•\thttps://www.data.gov/\n",
        "\n",
        "•\thttps://opendata.cityofnewyork.us/\n",
        "\n",
        "•\thttps://datasetsearch.research.google.com/\n",
        "\n",
        "•\thttps://archive.ics.uci.edu/ml/index.php\n",
        "\n",
        "### **Resources:**\n",
        "\n",
        "•\thttps://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html\n",
        "\n",
        "•\thttps://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html\n",
        "\n",
        "\n",
        "### **Headings or comments**\n",
        "**You are required to make use of comments, or headings for each section.  You must explain what your code is doing, and the results of running your code.**  Act as if you were giving this assignment to your manager - you must include clear and descriptive information for each section.\n",
        "\n",
        "### **You may work as a group or indivdually on this assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW3w6p8rqgxu"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this section, please describe the dataset you are using.  Include a link to the source of this data.  You should also provide some explanation on why you choose this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0PnfMOFzOXz"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bp8cdDxDs2t"
      },
      "source": [
        "______________\n",
        "# Data Exploration\n",
        "Import your dataset into your .ipynb, create dataframes, and explore your data.  \n",
        "\n",
        "Include:\n",
        "\n",
        "* Summary statistics means, medians, quartiles,\n",
        "* Missing value information\n",
        "* Any other relevant information about the dataset.  \n",
        "\n",
        "Steps done in this sections described below:\n",
        "\n",
        "Loading the Dataset: The dataset was loaded directly from the provided GitHub link using pandas.read_csv().\n",
        "\n",
        "Summary Statistics performed: Summary statistics, including mean, median, and quartiles for numerical columns, were computed using describe() to understand the central tendency and distribution.\n",
        "\n",
        "Missing Value Information: The amount of missing data in each column was assessed using isnull().sum(), which helped identify columns that require cleaning or imputation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OJmbafkEhhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732f0045-7e3e-4a83-e8ea-f154f25116c6"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/Jomifum/Assignment7D602/main/Air_Quality.csv\"\n",
        "dataset = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Original Dataset:\")\n",
        "print(dataset.head(10))\n",
        "\n",
        "# Summary statistics\n",
        "summary_stats = dataset.describe(include='all')\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(summary_stats)\n",
        "\n",
        "# Missing value information\n",
        "missing_values = dataset.isnull().sum()\n",
        "print(\"\\nMissing Values Information:\")\n",
        "print(missing_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "   Unique ID  Indicator ID                                   Name  \\\n",
            "0     179772           640  Boiler Emissions- Total SO2 Emissions   \n",
            "1     179785           640  Boiler Emissions- Total SO2 Emissions   \n",
            "2     178540           365                Fine particles (PM 2.5)   \n",
            "3     178561           365                Fine particles (PM 2.5)   \n",
            "4     823217           365                Fine particles (PM 2.5)   \n",
            "5     177910           365                Fine particles (PM 2.5)   \n",
            "6     177952           365                Fine particles (PM 2.5)   \n",
            "7     177973           365                Fine particles (PM 2.5)   \n",
            "8     177931           365                Fine particles (PM 2.5)   \n",
            "9     742274           365                Fine particles (PM 2.5)   \n",
            "\n",
            "          Measure Measure Info Geo Type Name  Geo Join ID  \\\n",
            "0  Number per km2       number         UHF42        409.0   \n",
            "1  Number per km2       number         UHF42        209.0   \n",
            "2            Mean       mcg/m3         UHF42        209.0   \n",
            "3            Mean       mcg/m3         UHF42        409.0   \n",
            "4            Mean       mcg/m3         UHF42        409.0   \n",
            "5            Mean       mcg/m3         UHF42        209.0   \n",
            "6            Mean       mcg/m3         UHF42        209.0   \n",
            "7            Mean       mcg/m3         UHF42        409.0   \n",
            "8            Mean       mcg/m3         UHF42        409.0   \n",
            "9            Mean       mcg/m3         UHF42        410.0   \n",
            "\n",
            "            Geo Place Name          Time Period  Start_Date  Data Value  \\\n",
            "0         Southeast Queens                 2015  01/01/2015         0.3   \n",
            "1  Bensonhurst - Bay Ridge                 2015  01/01/2015         1.2   \n",
            "2  Bensonhurst - Bay Ridge  Annual Average 2012  12/01/2011         8.6   \n",
            "3         Southeast Queens  Annual Average 2012  12/01/2011         8.0   \n",
            "4         Southeast Queens          Summer 2022  06/01/2022         6.1   \n",
            "5  Bensonhurst - Bay Ridge          Summer 2012  06/01/2012        10.0   \n",
            "6  Bensonhurst - Bay Ridge          Summer 2013  06/01/2013         9.8   \n",
            "7         Southeast Queens          Summer 2013  06/01/2013         9.8   \n",
            "8         Southeast Queens          Summer 2012  06/01/2012         9.6   \n",
            "9                Rockaways          Summer 2021  06/01/2021         7.2   \n",
            "\n",
            "   Message  \n",
            "0      NaN  \n",
            "1      NaN  \n",
            "2      NaN  \n",
            "3      NaN  \n",
            "4      NaN  \n",
            "5      NaN  \n",
            "6      NaN  \n",
            "7      NaN  \n",
            "8      NaN  \n",
            "9      NaN  \n",
            "\n",
            "Summary Statistics:\n",
            "            Unique ID  Indicator ID                    Name Measure  \\\n",
            "count    18025.000000  18025.000000                   18025   18025   \n",
            "unique            NaN           NaN                      18       8   \n",
            "top               NaN           NaN  Nitrogen dioxide (NO2)    Mean   \n",
            "freq              NaN           NaN                    5922   13959   \n",
            "mean    426387.692705    434.830180                     NaN     NaN   \n",
            "std     250489.450630    115.852371                     NaN     NaN   \n",
            "min     121644.000000    365.000000                     NaN     NaN   \n",
            "25%     175303.000000    365.000000                     NaN     NaN   \n",
            "50%     410803.000000    375.000000                     NaN     NaN   \n",
            "75%     649893.000000    386.000000                     NaN     NaN   \n",
            "max     828353.000000    661.000000                     NaN     NaN   \n",
            "\n",
            "       Measure Info Geo Type Name   Geo Join ID    Geo Place Name Time Period  \\\n",
            "count         18025         18025  1.801600e+04             18016       18025   \n",
            "unique            8             5           NaN               114          55   \n",
            "top             ppb         UHF42           NaN  Southeast Queens   2017-2019   \n",
            "freq           8037          7140           NaN               269         489   \n",
            "mean            NaN           NaN  5.906303e+05               NaN         NaN   \n",
            "std             NaN           NaN  7.769549e+06               NaN         NaN   \n",
            "min             NaN           NaN  1.000000e+00               NaN         NaN   \n",
            "25%             NaN           NaN  2.020000e+02               NaN         NaN   \n",
            "50%             NaN           NaN  3.030000e+02               NaN         NaN   \n",
            "75%             NaN           NaN  4.040000e+02               NaN         NaN   \n",
            "max             NaN           NaN  1.051061e+08               NaN         NaN   \n",
            "\n",
            "        Start_Date    Data Value  Message  \n",
            "count        18025  18025.000000      0.0  \n",
            "unique          43           NaN      NaN  \n",
            "top     01/01/2015           NaN      NaN  \n",
            "freq           906           NaN      NaN  \n",
            "mean           NaN     21.428616      NaN  \n",
            "std            NaN     23.999345      NaN  \n",
            "min            NaN      0.000000      NaN  \n",
            "25%            NaN      8.900000      NaN  \n",
            "50%            NaN     15.200000      NaN  \n",
            "75%            NaN     26.700000      NaN  \n",
            "max            NaN    424.700000      NaN  \n",
            "\n",
            "Missing Values Information:\n",
            "Unique ID             0\n",
            "Indicator ID          0\n",
            "Name                  0\n",
            "Measure               0\n",
            "Measure Info          0\n",
            "Geo Type Name         0\n",
            "Geo Join ID           9\n",
            "Geo Place Name        9\n",
            "Time Period           0\n",
            "Start_Date            0\n",
            "Data Value            0\n",
            "Message           18025\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCSLIafaEGVK"
      },
      "source": [
        "# Data Wrangling\n",
        "Create a subset of your original data and perform the following.  \n",
        "\n",
        "1. Modify multiple column names:\n",
        "Renaming Columns: The columns were renamed for consistency. Spaces were replaced with underscores, and all letters were converted to lowercase using a list comprehension.\n",
        "\n",
        "2. Look at the structure of your data – are any variables improperly coded? Such as strings or characters? Convert to correct structure if needed\n",
        "\n",
        "Checking and Correcting Data Types: Column data types were reviewed using dtypes, and any necessary conversions were made using pd.to_numeric() and pd.to_datetime().\n",
        "\n",
        "3. Fix missing and invalid values in data.\n",
        "Handling Missing Values was used: Missing values were filled out using fillna() for the data_value column, setting missing entries to 0 where appropriate.\n",
        "\n",
        "4. Create new columns based on existing columns or calculations.\n",
        "Creating New Columns: A new column, year, was extracted from the start_date column using dt.year.\n",
        "\n",
        "5. Drop column(s) from your dataset.\n",
        "Dropping Unnecessary Columns: The message column was dropped using drop(), as it did not add value to the analysis.\n",
        "\n",
        "6. Drop a row(s) from your dataset.\n",
        "Dropping Rows with Missing Values: Rows with any remaining missing values were removed using dropna().\n",
        "\n",
        "7. Sort your data based on multiple variables.\n",
        "\n",
        "Sorting Data: The dataset was sorted based on geo_place_name and time_period using sort_values().\n",
        "\n",
        "8. Filter your data based on some condition.\n",
        "Filtering Data: Data was filtered for a specific condition (e.g., the year 2015) using loc[].\n",
        "\n",
        "9. Convert all the string values to upper or lower cases in one column.\n",
        "String Manipulation: All string values in the geo_place_name column were converted to lowercase using str.lower().\n",
        "\n",
        "10. Check whether numeric values are present in a given column of your dataframe.\n",
        "Numeric Check: Ensured that all values in the data_value column were numeric using pd.to_numeric().\n",
        "\n",
        "11. Group your dataset by one column, and get the mean, min, and max values by group.\n",
        "  * Groupby()\n",
        "  * agg() or .apply()\n",
        "\n",
        "Grouping and Aggregation: The dataset was grouped by geo_place_name and year to calculate the mean, min, and max of data_value using groupby() and agg().\n",
        "\n",
        "12. Group your dataset by two columns and then sort the aggregated results within the groups.\n",
        "For this part the dataset was grouped by geo_place_name and year to calculate the mean, min, and max od data_value usign groupby() and agg() also sort_values() was used to group the two columns geo_place_name and year.\n",
        "\n",
        "**You are free (and should) to add on to these questions.  Please clearly indicate in your assignment your answers to these questions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VWWvvynEiQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e40e6d-7d5f-4025-ace0-045a7611fbd9"
      },
      "source": [
        "# Rename columns for consistency\n",
        "dataset.columns = [col.strip().replace(\" \", \"_\").lower() for col in dataset.columns]\n",
        "\n",
        "# Check the structure of the data\n",
        "print(\"\\nData Types:\")\n",
        "print(dataset.dtypes)\n",
        "\n",
        "# Convert columns to appropriate data types\n",
        "dataset['unique_id'] = pd.to_numeric(dataset['unique_id'], errors='coerce')\n",
        "dataset['indicator_id'] = pd.to_numeric(dataset['indicator_id'], errors='coerce')\n",
        "dataset['geo_join_id'] = pd.to_numeric(dataset['geo_join_id'], errors='coerce')\n",
        "dataset['data_value'] = pd.to_numeric(dataset['data_value'], errors='coerce')\n",
        "dataset['start_date'] = pd.to_datetime(dataset['start_date'], errors='coerce')\n",
        "\n",
        "# Fix missing values (example: filling NaN with 0 or other appropriate values)\n",
        "dataset.fillna({'data_value': 0}, inplace=True)\n",
        "\n",
        "# Create new column based on existing columns\n",
        "dataset['year'] = dataset['start_date'].dt.year\n",
        "\n",
        "# Drop unnecessary columns\n",
        "dataset.drop(columns=['message'], inplace=True)\n",
        "\n",
        "# Drop rows with any missing values\n",
        "dataset.dropna(inplace=True)\n",
        "\n",
        "# Sort data based on multiple variables\n",
        "sorted_data = dataset.sort_values(by=['geo_place_name', 'time_period'])\n",
        "\n",
        "# Filter data based on some condition (example: filter for year 2015)\n",
        "filtered_data = dataset[dataset['year'] == 2015]\n",
        "\n",
        "# Convert string values to lower case in one column\n",
        "dataset['geo_place_name'] = dataset['geo_place_name'].str.lower()\n",
        "\n",
        "# Check for numeric values in a column\n",
        "numeric_check = pd.to_numeric(dataset['data_value'], errors='coerce')\n",
        "print(\"\\nNumeric Check in 'data_value' Column:\")\n",
        "print(numeric_check.notnull().all())\n",
        "\n",
        "# Group data by one column and get mean, min, and max values\n",
        "grouped_data = dataset.groupby('geo_place_name')['data_value'].agg(['mean', 'min', 'max'])\n",
        "\n",
        "# Group data by two columns and sort within groups\n",
        "grouped_sorted_data = dataset.groupby(['geo_place_name', 'year'])['data_value'].agg(['mean', 'min', 'max']).sort_values(by=['geo_place_name', 'year'])\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nRenamed Columns and Cleaned Data:\")\n",
        "print(dataset.head(10))\n",
        "\n",
        "print(\"\\nGrouped Data by 'geo_place_name':\")\n",
        "print(grouped_data.head(10))\n",
        "\n",
        "print(\"\\nGrouped and Sorted Data by 'geo_place_name' and 'year':\")\n",
        "print(grouped_sorted_data.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Types:\n",
            "unique_id           int64\n",
            "indicator_id        int64\n",
            "name               object\n",
            "measure            object\n",
            "measure_info       object\n",
            "geo_type_name      object\n",
            "geo_join_id       float64\n",
            "geo_place_name     object\n",
            "time_period        object\n",
            "start_date         object\n",
            "data_value        float64\n",
            "message           float64\n",
            "dtype: object\n",
            "\n",
            "Numeric Check in 'data_value' Column:\n",
            "True\n",
            "\n",
            "Renamed Columns and Cleaned Data:\n",
            "   unique_id  indicator_id                                   name  \\\n",
            "0     179772           640  Boiler Emissions- Total SO2 Emissions   \n",
            "1     179785           640  Boiler Emissions- Total SO2 Emissions   \n",
            "2     178540           365                Fine particles (PM 2.5)   \n",
            "3     178561           365                Fine particles (PM 2.5)   \n",
            "4     823217           365                Fine particles (PM 2.5)   \n",
            "5     177910           365                Fine particles (PM 2.5)   \n",
            "6     177952           365                Fine particles (PM 2.5)   \n",
            "7     177973           365                Fine particles (PM 2.5)   \n",
            "8     177931           365                Fine particles (PM 2.5)   \n",
            "9     742274           365                Fine particles (PM 2.5)   \n",
            "\n",
            "          measure measure_info geo_type_name  geo_join_id  \\\n",
            "0  Number per km2       number         UHF42        409.0   \n",
            "1  Number per km2       number         UHF42        209.0   \n",
            "2            Mean       mcg/m3         UHF42        209.0   \n",
            "3            Mean       mcg/m3         UHF42        409.0   \n",
            "4            Mean       mcg/m3         UHF42        409.0   \n",
            "5            Mean       mcg/m3         UHF42        209.0   \n",
            "6            Mean       mcg/m3         UHF42        209.0   \n",
            "7            Mean       mcg/m3         UHF42        409.0   \n",
            "8            Mean       mcg/m3         UHF42        409.0   \n",
            "9            Mean       mcg/m3         UHF42        410.0   \n",
            "\n",
            "            geo_place_name          time_period start_date  data_value  year  \n",
            "0         southeast queens                 2015 2015-01-01         0.3  2015  \n",
            "1  bensonhurst - bay ridge                 2015 2015-01-01         1.2  2015  \n",
            "2  bensonhurst - bay ridge  Annual Average 2012 2011-12-01         8.6  2011  \n",
            "3         southeast queens  Annual Average 2012 2011-12-01         8.0  2011  \n",
            "4         southeast queens          Summer 2022 2022-06-01         6.1  2022  \n",
            "5  bensonhurst - bay ridge          Summer 2012 2012-06-01        10.0  2012  \n",
            "6  bensonhurst - bay ridge          Summer 2013 2013-06-01         9.8  2013  \n",
            "7         southeast queens          Summer 2013 2013-06-01         9.8  2013  \n",
            "8         southeast queens          Summer 2012 2012-06-01         9.6  2012  \n",
            "9                rockaways          Summer 2021 2021-06-01         7.2  2021  \n",
            "\n",
            "Grouped Data by 'geo_place_name':\n",
            "                                         mean  min    max\n",
            "geo_place_name                                           \n",
            "bay ridge and dyker heights (cd10)  18.738182  1.5   84.0\n",
            "bayside - little neck               15.310588  0.0   85.9\n",
            "bayside and little neck (cd11)      17.996364  1.2   81.2\n",
            "bayside little neck-fresh meadows   15.822222  5.6   33.7\n",
            "bedford stuyvesant (cd3)            19.417273  1.4   69.4\n",
            "bedford stuyvesant - crown heights  27.130112  0.1  213.9\n",
            "belmont and east tremont (cd6)      20.756364  1.6  104.9\n",
            "bensonhurst (cd11)                  17.238182  1.0   48.6\n",
            "bensonhurst - bay ridge             16.325279  0.2   73.4\n",
            "borough park                        16.840892  0.2   69.7\n",
            "\n",
            "Grouped and Sorted Data by 'geo_place_name' and 'year':\n",
            "                                              mean   min   max\n",
            "geo_place_name                     year                       \n",
            "bay ridge and dyker heights (cd10) 2005  38.800000   3.4  58.4\n",
            "                                   2008  18.625000  10.2  28.4\n",
            "                                   2009  19.150000   9.4  27.8\n",
            "                                   2010  27.680000   3.7  70.2\n",
            "                                   2011  14.022222   1.5  32.5\n",
            "                                   2012  17.457143   8.4  33.0\n",
            "                                   2013  17.542857   8.8  30.3\n",
            "                                   2014  17.520000   8.5  30.7\n",
            "                                   2015  15.555556   7.4  31.8\n",
            "                                   2016  17.480000   7.5  33.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions  \n",
        "\n",
        "The analysis of the air quality dataset revealed significant geographical and temporal variations in pollutant levels, emphasizing the importance of monitoring and addressing air quality issues. Key observations included differences in SO2 emissions and PM 2.5 levels across various regions and years, with certain areas showing higher pollution levels. Data cleaning and preparation steps, such as renaming columns, handling missing values, and converting data types, ensured the integrity of the analysis and provided a reliable foundation for further exploration.\n",
        "\n",
        "Future analysis could delve deeper into time series analysis to identify long-term trends and seasonal variations in air quality. Geospatial analysis could visualize pollution hotspots, while correlation studies might uncover relationships between pollutants and factors like population density or industrial activity. Predictive modeling could help forecast future air quality levels, and comparative analysis could identify patterns and causes for variations across different regions. These additional analyses would offer more comprehensive insights into air quality trends and inform public health and environmental policies."
      ],
      "metadata": {
        "id": "tujjevRpXEen"
      }
    }
  ]
}